# requirements from task
The goal of this task is to write a piece of code that can generate a synthetic dataset representing the normal operation of a given ICS that looks as similar as possible to the corresponding original dataset. To this end, you have to implement your own Generative Adversarial Network (GAN) that can print out as output synthetically generated physical readings having the same shape as the original input dataset. In particular, you need to write a piece of code that satisfies the following requirements:
a) Your GAN should consist of two components: a discriminator and a generator. The discriminator should be a two-class classifier that is trained to differentiate between real data samples and fake data samples that are generated by the generator. The generator should be trained to create those fake data samples in a way that is as hard to distinguish from the real samples as possible.
b) Your discriminator should be a convolutional neural network (CNN) that consists of 8 convolutional layers with a LeakyReLU activation function. In addition, you should add a dropout layer after all convolutional layers except the first and last layers. Then, the output from the last convolutional layer should be passed to 4 fully connected layers with a ReLU activation function. The discriminator should output a single value in the range [0, 1) indicating how real the how real the input data is.
c) Your generator should be given a noise data as input and should operate as a reverse CNN that uses a method, called deconvolution, to transform the noise into meaningful physical readings. In particular, the generator should be initiated with 3 fully connected layers with a ReLU activation function that are followed by 9 convolutional layers with a ReLU activation function. In addition, the first 4 layers from these 9 convolutional layers should be preceded by an upsampling layer. The function used to generate the input noise data for the generator is of your choice.
d) For your generator, you should implement custom loss function that is computed on the input used for the first fully connected layer of the discriminator. This loss function should seek minimizing the difference between the features found in real data and the features found in its generated samples.
e) Finally, you should write piece of code that can perform hyperparameter tuning for your GAN, e.g., optimization of the parameters needed for your convolutional layers, number of training epochs, etc.
==============================
# model.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from .config import GANConfig

class Discriminator(nn.Module):
    def __init__(self, config: GANConfig):
        super().__init__()
        # 8 convolutional layers with LeakyReLU and dropouts
        self.conv_layers = nn.Sequential(
            # 1st conv layer (no dropout)
            nn.Conv1d(1, config.feature_dim, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            
            # 2nd conv layer with dropout
            nn.Conv1d(config.feature_dim, config.feature_dim * 2, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 3rd conv layer with dropout
            nn.Conv1d(config.feature_dim * 2, config.feature_dim * 4, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 4th conv layer with dropout
            nn.Conv1d(config.feature_dim * 4, config.feature_dim * 8, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 5th conv layer with dropout
            nn.Conv1d(config.feature_dim * 8, config.feature_dim * 16, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 6th conv layer with dropout
            nn.Conv1d(config.feature_dim * 16, config.feature_dim * 32, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 7th conv layer with dropout
            nn.Conv1d(config.feature_dim * 32, config.feature_dim * 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Dropout(config.dropout_rate),
            
            # 8th conv layer (no dropout)
            nn.Conv1d(config.feature_dim * 64, config.feature_dim * 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2)
        )
        
        # 4 fully connected layers with ReLU
        self.fc_layers = nn.Sequential(
            nn.Linear(config.feature_dim * 128, config.feature_dim * 64),
            nn.ReLU(),
            nn.Linear(config.feature_dim * 64, config.feature_dim * 32),
            nn.ReLU(),
            nn.Linear(config.feature_dim * 32, config.feature_dim * 16),
            nn.ReLU(),
            nn.Linear(config.feature_dim * 16, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # Ensure input is right shape (batch_size, channels, sequence_length)
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        return self.fc_layers(x)

class Generator(nn.Module):
    def __init__(self, config: GANConfig):
        super().__init__()
        
        # 3 fully connected layers with ReLU
        self.fc_layers = nn.Sequential(
            nn.Linear(config.input_dim, config.feature_dim * 16),
            nn.ReLU(),
            nn.Linear(config.feature_dim * 16, config.feature_dim * 32),
            nn.ReLU(),
            nn.Linear(config.feature_dim * 32, config.feature_dim * 64),
            nn.ReLU()
        )
        
        # 9 convolutional layers with 4 initial layers preceded by upsampling
        self.deconv_layers = nn.Sequential(
            # Upsample and first 4 layers with upsampling
            nn.Upsample(scale_factor=2),
            nn.ConvTranspose1d(config.feature_dim * 64, config.feature_dim * 32, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.Upsample(scale_factor=2),
            nn.ConvTranspose1d(config.feature_dim * 32, config.feature_dim * 16, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.Upsample(scale_factor=2),
            nn.ConvTranspose1d(config.feature_dim * 16, config.feature_dim * 8, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.Upsample(scale_factor=2),
            nn.ConvTranspose1d(config.feature_dim * 8, config.feature_dim * 4, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            # Remaining 5 layers without upsampling
            nn.ConvTranspose1d(config.feature_dim * 4, config.feature_dim * 2, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.ConvTranspose1d(config.feature_dim * 2, config.feature_dim, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.ConvTranspose1d(config.feature_dim, config.feature_dim // 2, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            
            nn.ConvTranspose1d(config.feature_dim // 2, 1, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def forward(self, x):
        # Transform noise through fully connected layers
        x = self.fc_layers(x)
        
        # Reshape for deconvolution layers
        x = x.view(x.size(0), -1, 1)
        
        # Generate synthetic data
        return self.deconv_layers(x)

def custom_generator_loss(real_features, generated_features):
    """
    Custom loss function that minimizes the difference between 
    features of real and generated data.
    
    Args:
    - real_features: Features extracted from real data
    - generated_features: Features extracted from generated data
    
    Returns:
    - Loss value representing the feature difference
    """
    # Mean squared error between feature representations
    return F.mse_loss(real_features, generated_features)

# config.py
from dataclasses import dataclass
from pathlib import Path
import os

# Define paths
BASE_DIR = Path(__file__).parent.parent.parent
DATA_PATH = BASE_DIR / 'data' / 'gan'
os.makedirs(BASE_DIR / 'results', exist_ok=True)
os.makedirs(BASE_DIR / 'saved_model', exist_ok=True)

@dataclass
class GANConfig:
    # Model parameters
    feature_dim: int = 32
    input_dim: int = 100
    dropout_rate: float = 0.3
    
    # Training parameters
    batch_size: int = 16
    num_epochs: int = 2
    learning_rate_g: float = 0.0002
    learning_rate_d: float = 0.0001
    
    # Data generation parameters
    samples_per_day: int = 300
    days_to_generate: int = 3
    
    # Paths
    train_set_1_path: Path = DATA_PATH / 'train1_clean.csv'
    train_set_2_path: Path = DATA_PATH / 'train4_clean.csv'
    model_save_path: Path = BASE_DIR / 'saved_model'
    synthetic_data_path: Path = DATA_PATH / 'synthetic_data.csv'
    ks_summary_path: Path = BASE_DIR/ 'results' / 'ks_summary.csv'

    # Check if files exist
    files_to_check = [
        train_set_1_path,
        train_set_2_path
    ]

    def __post_init__(self):
        for file_path in self.files_to_check:
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Error: File '{file_path}' does not exist.")


#train.py
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Tuple
from .models import Generator, Discriminator
from .data_utils import DataProcessor
from .config import GANConfig
import pandas as pd

class GANTrainer:
    def __init__(self, config: GANConfig):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.data_processor = DataProcessor(config)
        
    def save_model(self, model: nn.Module, filename: str) -> None:
        self.config.model_save_path.mkdir(parents=True, exist_ok=True)
        save_path = self.config.model_save_path / filename
        torch.save({
            'model_state_dict': model.state_dict(),
            'input_dim': self.config.input_dim,
        }, save_path)
        print(f"Model saved to {save_path}")

    def train(self) -> Tuple[Generator, pd.DataFrame, pd.DataFrame]:
        train_set_1, train_set_2 = self.data_processor.load_and_preprocess_data()
        tensor_data = self.data_processor.normalize_data(train_set_2)
        train_loader = self.data_processor.create_dataloader(tensor_data)

        discriminator = Discriminator(self.config).to(self.device)
        generator = Generator(self.config).to(self.device)
        
        criterion = nn.BCELoss()
        optimizer_d = optim.Adam(discriminator.parameters(), lr=self.config.learning_rate_d, betas=(0.5, 0.999))
        optimizer_g = optim.Adam(generator.parameters(), lr=self.config.learning_rate_g, betas=(0.5, 0.999))

        self._train_gan(train_loader, discriminator, generator, criterion, optimizer_d, optimizer_g)
        self.save_model(generator, 'generator.pth')
        
        return generator, train_set_1, train_set_2

    def _train_gan(self, train_loader, discriminator, generator, criterion, optimizer_d, optimizer_g):
        for epoch in range(self.config.num_epochs):
            for i, batch in enumerate(train_loader):
                real_data = batch[0].to(self.device)
                batch_size = real_data.size(0)
                
                # Train Discriminator
                optimizer_d.zero_grad()
                real_labels = torch.full((batch_size, 1), 0.9).to(self.device)
                fake_labels = torch.full((batch_size, 1), 0.1).to(self.device)
                
                outputs = discriminator(real_data)
                d_loss_real = criterion(outputs, real_labels)
                
                noise = torch.randn(batch_size, self.config.input_dim).to(self.device)
                fake_data = generator(noise)
                outputs = discriminator(fake_data.detach())
                d_loss_fake = criterion(outputs, fake_labels)
                
                d_loss = d_loss_real + d_loss_fake
                d_loss.backward()
                optimizer_d.step()
                
                # Train Generator
                optimizer_g.zero_grad()
                outputs = discriminator(fake_data)
                g_loss = criterion(outputs, real_labels)
                g_loss.backward()
                optimizer_g.step()
                
                if i % 50 == 0:
                    print(f"Epoch [{epoch+1}/{self.config.num_epochs}], "
                          f"Batch [{i+1}], d_loss: {d_loss.item():.4f}, "
                          f"g_loss: {g_loss.item():.4f}")