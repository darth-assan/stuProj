{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cefab19-fda9-417b-aa6d-b4c5149dd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries required \n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ae6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the data\n",
    "class DatasetProcessor:\n",
    "    \"\"\"A class to process HAI datasets and calculate Euclidean distances.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str, output_dir: str):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self._setup_logging()\n",
    "        \n",
    "    def _setup_logging(self) -> None:\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_physical_columns(df: pd.DataFrame) -> List[str]:\n",
    "        return [\n",
    "            col for col in df.columns\n",
    "            if not re.search(r'(time|timestamp|attack|Attack)', col, re.IGNORECASE)\n",
    "        ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_attack_columns(df: pd.DataFrame) -> List[str]:\n",
    "        return [\n",
    "            col for col in df.columns\n",
    "            if re.search(r'attack', col, re.IGNORECASE)\n",
    "        ]\n",
    "    \n",
    "    def filter_attack_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        attack_columns = self._get_attack_columns(df)\n",
    "        if attack_columns:\n",
    "            return df[(df[attack_columns] == 0).all(axis=1)].copy()\n",
    "        return df.copy()\n",
    "    \n",
    "    def filter_non_numeric_and_outliers(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        physical_columns = self._get_physical_columns(df)\n",
    "        df[physical_columns] = df[physical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "        df = df.dropna(subset=physical_columns).copy()\n",
    "        \n",
    "        Q1 = df[physical_columns].quantile(0.25)\n",
    "        Q3 = df[physical_columns].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        return df[~((df[physical_columns] < lower_bound) | \n",
    "                   (df[physical_columns] > upper_bound)).any(axis=1)]\n",
    "    \n",
    "    def normalize_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        physical_columns = self._get_physical_columns(df)\n",
    "        scaler = MinMaxScaler()\n",
    "        df[physical_columns] = scaler.fit_transform(df[physical_columns])\n",
    "        return df\n",
    "    \n",
    "    def calculate_distances(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        physical_columns = self._get_physical_columns(df)\n",
    "        data = df[physical_columns].values\n",
    "        differences = np.diff(data, axis=0)\n",
    "        return np.sqrt(np.sum(differences ** 2, axis=1))\n",
    "    \n",
    "    def process_file(self, file_path: Path) -> None:\n",
    "        try:\n",
    "            self.logger.info(f\"Processing file: {file_path}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = self.filter_attack_data(df)\n",
    "            df = self.filter_non_numeric_and_outliers(df)\n",
    "            df = self.normalize_data(df)\n",
    "            distances = self.calculate_distances(df)\n",
    "            \n",
    "            dataset_version = file_path.parent.name\n",
    "            output_dir = self.output_dir / dataset_version\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            output_file = output_dir / f\"{file_path.name}_distances.csv\"\n",
    "            pd.DataFrame(distances, columns=[\"Euclidean_Distance\"]).to_csv(\n",
    "                output_file, index=False\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Saved distances to: {output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    def process_datasets(self) -> None:\n",
    "        for file_path in self.base_dir.rglob(\"*\"):\n",
    "            if file_path.is_file() and re.search(r'(test|train)', file_path.name, re.IGNORECASE):\n",
    "                self.process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612e2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating histograms\n",
    "\n",
    "# Directory paths\n",
    "DISTANCES_DIR = os.path.expanduser(\"~/dev/stuProj/data/distances\")\n",
    "\n",
    "def load_distances():\n",
    "    # ... existing load_distances function remains the same ...\n",
    "    train_distances = []\n",
    "    test_distances = []\n",
    "\n",
    "    for dataset_version in os.listdir(DISTANCES_DIR):\n",
    "        version_path = os.path.join(DISTANCES_DIR, dataset_version)\n",
    "        \n",
    "        if not os.path.isdir(version_path):\n",
    "            continue\n",
    "            \n",
    "        for file in os.listdir(version_path):\n",
    "            file_path = os.path.join(version_path, file)\n",
    "            try:\n",
    "                if \"train\" in file.lower():\n",
    "                    distances = pd.read_csv(file_path)[\"Euclidean_Distance\"].tolist()\n",
    "                    train_distances.extend(distances)\n",
    "                    print(f\"Loaded train data from: {file_path}\")\n",
    "                elif \"test\" in file.lower():\n",
    "                    distances = pd.read_csv(file_path)[\"Euclidean_Distance\"].tolist()\n",
    "                    test_distances.extend(distances)\n",
    "                    print(f\"Loaded test data from: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "    \n",
    "    return train_distances, test_distances\n",
    "\n",
    "def plot_histograms_matplotlib(train_distances, test_distances, num_bins=50):\n",
    "    \"\"\"\n",
    "    Create and save histograms using matplotlib\n",
    "    \"\"\"\n",
    "    # Set style to a built-in style\n",
    "    plt.style.use('ggplot')  # Alternative options: 'classic', 'default', 'bmh', 'fivethirtyeight'\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Plot train data histogram\n",
    "    if train_distances:\n",
    "        ax1.hist(train_distances, bins=num_bins, color='blue', alpha=0.7)\n",
    "        ax1.set_title('Train Set Euclidean Distance Histogram')\n",
    "        ax1.set_xlabel('Distance')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No train distances found', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # Plot test data histogram\n",
    "    if test_distances:\n",
    "        ax2.hist(test_distances, bins=num_bins, color='green', alpha=0.7)\n",
    "        ax2.set_title('Test Set Euclidean Distance Histogram')\n",
    "        ax2.set_xlabel('Distance')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No test distances found', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    output_dir = os.path.expanduser(\"~/dev/stuProj/results\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, 'distance_histograms.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Histograms saved to: {os.path.join(output_dir, 'distance_histograms.png')}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34953ebb",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "1. Update the `BASE_DIR` path to poin to the original dataset on your computer.\n",
    "2. Set the `OUTPUT_DIR` to where you wish to save the eucliden distances calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb53c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the code\n",
    "BASE_DIR = \"path/to/original/data\"\n",
    "OUTPUT_DIR = \"path/to/save/distances\"\n",
    "\n",
    "# Running the processor\n",
    "processor = DatasetProcessor(BASE_DIR, OUTPUT_DIR)\n",
    "processor.process_datasets()\n",
    "\n",
    "# Generating histograms\n",
    "train_distances, test_distances = load_distances()\n",
    "plot_histograms_matplotlib(train_distances, test_distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
